#pragma clang diagnostic ignored "-Wmissing-prototypes"
#pragma clang diagnostic ignored "-Wmissing-braces"
#pragma clang diagnostic ignored "-Wunused-variable"

#include <metal_stdlib>
#include <simd/simd.h>
#include <metal_atomic>

using namespace metal;

template<typename T, size_t Num>
struct spvUnsafeArray
{
    T elements[Num ? Num : 1];
    
    thread T& operator [] (size_t pos) thread
    {
        return elements[pos];
    }
    constexpr const thread T& operator [] (size_t pos) const thread
    {
        return elements[pos];
    }
    
    device T& operator [] (size_t pos) device
    {
        return elements[pos];
    }
    constexpr const device T& operator [] (size_t pos) const device
    {
        return elements[pos];
    }
    
    constexpr const constant T& operator [] (size_t pos) const constant
    {
        return elements[pos];
    }
    
    threadgroup T& operator [] (size_t pos) threadgroup
    {
        return elements[pos];
    }
    constexpr const threadgroup T& operator [] (size_t pos) const threadgroup
    {
        return elements[pos];
    }
};

template<typename T>
inline T spvSubgroupShuffle(T value, ushort lane)
{
    return simd_shuffle(value, lane);
}

template<>
inline bool spvSubgroupShuffle(bool value, ushort lane)
{
    return !!simd_shuffle((ushort)value, lane);
}

template<uint N>
inline vec<bool, N> spvSubgroupShuffle(vec<bool, N> value, ushort lane)
{
    return (vec<bool, N>)simd_shuffle((vec<ushort, N>)value, lane);
}

struct StateBuf
{
    uint part_counter;
    uint state[1];
};

struct InBuf
{
    uint4 inbuf[1];
};

struct OutBuf
{
    uint4 outbuf[1];
};

kernel void main0(const device InBuf& _69 [[buffer(0)]], device OutBuf& _596 [[buffer(1)]], volatile device StateBuf& _23 [[buffer(2)]], uint3 gl_LocalInvocationID [[thread_position_in_threadgroup]], uint gl_SubgroupInvocationID [[thread_index_in_simdgroup]], uint gl_SubgroupSize [[thread_execution_width]])
{
    threadgroup uint s_broadcast;
    threadgroup uint s_lock;
    threadgroup spvUnsafeArray<uint, 128> s_reduce;
    threadgroup spvUnsafeArray<uint, 128> s_fallback;
    if (gl_LocalInvocationID.x == 0u)
    {
        uint _29 = atomic_fetch_add_explicit((volatile device atomic_uint*)&_23.part_counter, 1u, memory_order_relaxed);
        s_broadcast = _29;
        s_lock = 0u;
    }
    threadgroup_barrier(mem_flags::mem_threadgroup);
    uint part_id = s_broadcast;
    uint offset = (gl_SubgroupInvocationID + (((gl_LocalInvocationID.x / gl_SubgroupSize) * gl_SubgroupSize) * 4u)) + (part_id * 2048u);
    spvUnsafeArray<uint4, 4> t_scan;
    for (uint i = 0u; i < 4u; i++)
    {
        t_scan[i] = _69.inbuf[offset];
        t_scan[i].y += t_scan[i].x;
        t_scan[i].z += t_scan[i].y;
        t_scan[i].w += t_scan[i].z;
        offset += gl_SubgroupSize;
    }
    uint prev = 0u;
    uint highest_lane = gl_SubgroupSize - 1u;
    for (uint i_1 = 0u; i_1 < 4u; i_1++)
    {
        uint t = simd_prefix_exclusive_sum(t_scan[i_1].w);
        t_scan[i_1] += uint4(t + prev);
        prev = spvSubgroupShuffle(t_scan[i_1].w, highest_lane);
    }
    if (gl_SubgroupInvocationID == 0u)
    {
        s_reduce[gl_LocalInvocationID.x / gl_SubgroupSize] = prev;
    }
    threadgroup_barrier(mem_flags::mem_threadgroup);
    uint wg_red = 0u;
    if (gl_SubgroupSize >= 32u)
    {
        if (gl_LocalInvocationID.x < gl_SubgroupSize)
        {
            bool pred = gl_LocalInvocationID.x < (512u / gl_SubgroupSize);
            uint _175;
            if (pred)
            {
                _175 = s_reduce[gl_LocalInvocationID.x];
            }
            else
            {
                _175 = 0u;
            }
            wg_red = simd_prefix_inclusive_sum(_175);
            if (pred)
            {
                s_reduce[gl_LocalInvocationID.x] = wg_red;
            }
            wg_red = spvSubgroupShuffle(wg_red, (512u / gl_SubgroupSize) - 1u);
        }
    }
    else
    {
        uint red_size = 512u / gl_SubgroupSize;
        bool pred_1 = gl_LocalInvocationID.x < red_size;
        if (pred_1)
        {
            wg_red = s_reduce[gl_LocalInvocationID.x];
        }
        uint lg_red_size = uint(int(popcount(red_size - 1u)));
        for (uint i_2 = 0u; i_2 < lg_red_size; i_2++)
        {
            threadgroup_barrier(mem_flags::mem_threadgroup);
            if ((gl_LocalInvocationID.x >= (1u << i_2)) && pred_1)
            {
                wg_red += s_reduce[gl_LocalInvocationID.x - (1u << i_2)];
            }
            threadgroup_barrier(mem_flags::mem_threadgroup);
            if (pred_1)
            {
                s_reduce[gl_LocalInvocationID.x] = wg_red;
            }
        }
        threadgroup_barrier(mem_flags::mem_threadgroup);
        if (gl_LocalInvocationID.x == 0u)
        {
            wg_red = s_reduce[red_size - 1u];
        }
    }
    if (gl_LocalInvocationID.x == 0u)
    {
        atomic_store_explicit((volatile device atomic_uint*)&_23.state[part_id], (wg_red << uint(2)) | uint((part_id != 0u) ? 1 : 2), memory_order_relaxed);
    }
    if (part_id != 0u)
    {
        uint prev_reduction = 0u;
        uint lookback_id = part_id - 1u;
        uint _423;
        while (s_lock == 0u)
        {
            threadgroup_barrier(mem_flags::mem_threadgroup);
            if (gl_LocalInvocationID.x == 0u)
            {
                uint spin_count = 0u;
                while (spin_count < 4u)
                {
                    uint _309 = atomic_load_explicit((volatile device atomic_uint*)&_23.state[lookback_id], memory_order_relaxed);
                    uint flag_payload = _309;
                    if ((flag_payload & 3u) > 0u)
                    {
                        prev_reduction += (flag_payload >> uint(2));
                        if ((flag_payload & 3u) == 2u)
                        {
                            atomic_store_explicit((volatile device atomic_uint*)&_23.state[part_id], ((wg_red + prev_reduction) << uint(2)) | 2u, memory_order_relaxed);
                            s_broadcast = prev_reduction;
                            s_lock = 1u;
                            break;
                        }
                        if ((flag_payload & 3u) == 1u)
                        {
                            lookback_id--;
                            spin_count = 0u;
                        }
                    }
                    else
                    {
                        spin_count++;
                    }
                }
                if (s_lock == 0u)
                {
                    s_broadcast = lookback_id;
                }
            }
            threadgroup_barrier(mem_flags::mem_threadgroup);
            if (s_lock == 0u)
            {
                uint fallback_id = s_broadcast;
                uint f_end = (fallback_id + 1u) * 2048u;
                uint f_red = 0u;
                uint _364 = gl_LocalInvocationID.x + (fallback_id * 2048u);
                for (uint i_3 = _364; i_3 < f_end; i_3 += 512u)
                {
                    uint4 t_1 = _69.inbuf[i_3];
                    f_red += (((t_1.x + t_1.y) + t_1.z) + t_1.w);
                }
                uint f_sub_red = simd_sum(f_red);
                if (gl_SubgroupInvocationID == 0u)
                {
                    s_fallback[gl_LocalInvocationID.x / gl_SubgroupSize] = f_sub_red;
                }
                threadgroup_barrier(mem_flags::mem_threadgroup);
                if (gl_SubgroupSize >= 32u)
                {
                    if (gl_LocalInvocationID.x < gl_SubgroupSize)
                    {
                        bool pred_2 = gl_LocalInvocationID.x < (512u / gl_SubgroupSize);
                        if (pred_2)
                        {
                            _423 = s_fallback[gl_LocalInvocationID.x];
                        }
                        else
                        {
                            _423 = 0u;
                        }
                        f_red = simd_sum(_423);
                    }
                }
                else
                {
                    uint red_size_1 = 512u / gl_SubgroupSize;
                    bool pred_3 = gl_LocalInvocationID.x < red_size_1;
                    if (pred_3)
                    {
                        f_red = s_fallback[gl_LocalInvocationID.x];
                    }
                    uint lg_red_size_1 = uint(int(popcount(red_size_1 - 1u)));
                    for (uint i_4 = 0u; i_4 < lg_red_size_1; i_4++)
                    {
                        threadgroup_barrier(mem_flags::mem_threadgroup);
                        if ((gl_LocalInvocationID.x >= (1u << i_4)) && pred_3)
                        {
                            f_red += s_fallback[gl_LocalInvocationID.x - (1u << i_4)];
                        }
                        threadgroup_barrier(mem_flags::mem_threadgroup);
                        if (pred_3)
                        {
                            s_fallback[gl_LocalInvocationID.x] = f_red;
                        }
                    }
                    threadgroup_barrier(mem_flags::mem_threadgroup);
                    if (gl_LocalInvocationID.x == 0u)
                    {
                        f_red = s_fallback[(512u / gl_SubgroupSize) - 1u];
                    }
                }
                if (gl_LocalInvocationID.x == 0u)
                {
                    uint flag_payload_1 = (f_red << uint(2)) | uint((fallback_id != 0u) ? 1 : 2);
                    uint _517;
                    do
                    {
                        _517 = 0u;
                    } while (!atomic_compare_exchange_weak_explicit((volatile device atomic_uint*)&_23.state[fallback_id], &_517, flag_payload_1, memory_order_relaxed, memory_order_relaxed) && _517 == 0u);
                    uint prev_payload = _517;
                    if (prev_payload == 0u)
                    {
                        prev_reduction += f_red;
                    }
                    else
                    {
                        prev_reduction += (prev_payload >> uint(2));
                    }
                    bool _531 = fallback_id == 0u;
                    bool _538;
                    if (!_531)
                    {
                        _538 = (prev_payload & 3u) == 2u;
                    }
                    else
                    {
                        _538 = _531;
                    }
                    if (_538)
                    {
                        atomic_store_explicit((volatile device atomic_uint*)&_23.state[part_id], ((wg_red + prev_reduction) << uint(2)) | 2u, memory_order_relaxed);
                        s_broadcast = prev_reduction;
                        s_lock = 1u;
                    }
                    else
                    {
                        lookback_id--;
                    }
                }
                threadgroup_barrier(mem_flags::mem_threadgroup);
            }
        }
    }
    threadgroup_barrier(mem_flags::mem_threadgroup);
    uint _558;
    if ((gl_LocalInvocationID.x / gl_SubgroupSize) != 0u)
    {
        _558 = s_reduce[(gl_LocalInvocationID.x / gl_SubgroupSize) - 1u];
    }
    else
    {
        _558 = 0u;
    }
    uint prev_1 = _558 + s_broadcast;
    uint offset_1 = (gl_SubgroupInvocationID + (((gl_LocalInvocationID.x / gl_SubgroupSize) * gl_SubgroupSize) * 4u)) + (part_id * 2048u);
    for (uint i_5 = 0u; i_5 < 4u; i_5++)
    {
        _596.outbuf[offset_1] = t_scan[i_5] + uint4(prev_1);
        offset_1 += gl_SubgroupSize;
    }
}

